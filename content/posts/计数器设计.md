---
title: "计数器设计"
date: 2020-11-27T23:10:56+08:00
draft: false
categories: 
  - "系统设计"
tags: 
  - "计数器"
email: zengqiang96@gmail.com
---


在当今的互联网中，存在着很多技术器的场景，比如微博的点赞数，转发数，视频播放数，消息未读数等等

这些计数场景看似简单，但是它们有共同的特性：

1. 数据量大，这么多条微博，都得进行计数，可想而之
2. 写入数巨大，比如视频播放数，只要视频播放1次，计数就会发生变化
3. 读请求也很大，而且对接口性能要求也很高，比如消息未读数，即使用户不关心，但是还是会请求技术接口
4. 可用性和数据的准确性要求高

对于这种场景，我们应该如何设计呢？

<!--more-->

### **通用的计数场景**

最简单的方案

在t_weibo表中添加点赞，转发字段记录微博的计数信息，查询的时候用select出来就行

但是这个方案有很多问题

1. t_weibo表也在不停的添加，修改数据，现在吧计数字段加进来，计数也是变化频繁的，t_weibo所在的数据库不爆才怪
2. 扩展性的问题，如果需要添加一种计数类型，有需要添加一个字段，你想想业务发展起来，维护起来得多恐怖

那就吧计数字段单独弄成一张表

```
 select repost_count, comment_count, praise_count, view_count from t_weibo_count where weibo_id = xxx
```

单独抽出来之后，面对数据量大的问题，我们可以考虑分库分表：

1. 基于weibo_id进行hash来分库分表
2. 基于weibo创建时间来进行分裤分表

考虑到活跃的都是最新的weibo，如果按照时间来分库分表的话会造成访问不均匀的情况

接下来就是访问量巨大的问题，访问量分为读请求和写请求2种

对于读请求，如果每次我们都查询数据库，靠数据的索引来解决大量的读请求也是不现实的，这个时候我们可以考虑缓存，缓存一下查询过的计数信息，但是这样又会导致数据不一致的情况，我们可以直接放弃数据，直接使用redis作为计数的存储

对于写请求，可能一个明星发布了一条微博，瞬间有很多的转发，如何保证这种情况下的高可用呢 ，可以引入消息队列，将这些写请求缓存在消息队列中，计数服务消费消息进行计数的修改

其实还可以吧多条转发消息聚合成1次数据库修改，比如你收到了weibo_id为1的点赞10次，其实只需求update一次，将点赞的计数一次性+10就行了

其实使用redis作为计数存储，不想mysql可以分裤边表，redis使用的是内存，内存存储的成本还是很高的，而且weibo数很多，所以我们可以考虑将最新的weibo计数使用内存进行存储，哪些远古微博很少有人再访问了，所以可以考虑把这些数据存储到磁盘上

最后如果有能力可以对redis进行改造，针对计数这种场景优化一下redis内存的数据结构，进一步减少内存的占用

### **共享的计数**

前面介绍的场景是一种通用情况下的计数， 比如用户的未读消息，有人@你，评论你使用前面的那种方式进行计数就行，但是也存在一些场景，比如系统通知的未读数，我们不可能将这一条系统消息未读数给系统中所有的用户都加一遍是吧，如果我们有20亿用户，都去加1，怎么可能呢？

其实这种场景很简单，因为系统通知是共享的嘛，每个用户看到的都一样，所以系统消息只用存一份数据就行，问题是每个用户未读的消息不一样，我们只需要记录下每个用户已读系统消息的偏移就行了，未读数可以通过总数-已读偏移就出来了

### **个性化的计数**

前面介绍了2种场景下的计数，一种的通用的计数，一种是共享数据的计数，还有一种场景就是个性化的计数场景，比如weibo种信息流的未读数

信息流中的未读数是你关注人发送weibo，而你没有浏览的数据，这种场景下如何来计数呢？

首先使用一个通用计数器记录每个人的weibo数，然后对于个人把它看过的关注人的博文数记录一个快照，这样消息流种的未读数就是关注人的weibo数减去个人快照的总和

![信息流未读方案](/计数器设计/信息流未读方案.png)